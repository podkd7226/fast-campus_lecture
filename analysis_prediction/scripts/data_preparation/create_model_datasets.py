#!/usr/bin/env python3
"""
ì˜ˆì¸¡ ëª¨ë¸ì„ ìœ„í•œ ë³€ìˆ˜ ì„ íƒ ë° ë°ì´í„°ì…‹ ìƒì„±
ê²°ì¸¡ì¹˜ ë¶„ì„ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ 3ê°€ì§€ ë ˆë²¨ì˜ ë°ì´í„°ì…‹ ìƒì„±
"""

import pandas as pd
import numpy as np
import json
import matplotlib.pyplot as plt
import seaborn as sns
import platform
from pathlib import Path
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
if platform.system() == 'Darwin':  # macOS
    plt.rcParams['font.family'] = 'AppleGothic'
elif platform.system() == 'Windows':
    plt.rcParams['font.family'] = 'Malgun Gothic'
else:  # Linux
    plt.rcParams['font.family'] = 'NanumGothic'
plt.rcParams['axes.unicode_minus'] = False

# ê²½ë¡œ ì„¤ì •
BASE_DIR = Path(__file__).resolve().parent.parent.parent.parent
DATA_DIR = BASE_DIR / 'analysis_prediction' / 'data'
OUTPUT_DIR = BASE_DIR / 'analysis_prediction' / 'data'
FIGURES_DIR = BASE_DIR / 'analysis_prediction' / 'figures'

# ë””ë ‰í† ë¦¬ ìƒì„±
OUTPUT_DIR.mkdir(exist_ok=True)
FIGURES_DIR.mkdir(exist_ok=True)

# ë³€ìˆ˜ ì§‘í•© ì •ì˜ (ê²°ì¸¡ì¹˜ ë¶„ì„ ê¸°ë°˜)
VARIABLE_SETS = {
    'essential': {
        'description': 'í•„ìˆ˜ ë³€ìˆ˜ ì„¸íŠ¸ (ê²°ì¸¡ë¥  < 30%)',
        'lab_features': [
            'Hematocrit_51221_merged',  # 22.0% ê²°ì¸¡
            'Hemoglobin_51222',          # 23.2% ê²°ì¸¡
            'Creatinine_50912_merged',   # 23.9% ê²°ì¸¡
            'RDW_51277',                  # 24.2% ê²°ì¸¡
            'White_Blood_Cells_51301_merged',  # 24.2% ê²°ì¸¡
            'Urea_Nitrogen_51006_merged', # 24.2% ê²°ì¸¡
            'Potassium_50971_merged',     # 24.3% ê²°ì¸¡
            'Sodium_50983_merged',        # 25.0% ê²°ì¸¡
            'Glucose_50931'               # 25.9% ê²°ì¸¡ (ì£¼ìš” glucose ì»¬ëŸ¼ ì„ íƒ)
        ],
        'clinical_relevance': 'CBC, BMP ê¸°ë³¸ ê²€ì‚¬ - ëª¨ë“  ì…ì› í™˜ìì˜ í‘œì¤€ ê²€ì‚¬'
    },
    
    'extended': {
        'description': 'í™•ì¥ ë³€ìˆ˜ ì„¸íŠ¸ (ê²°ì¸¡ë¥  < 70%)',
        'lab_features': [
            # í•„ìˆ˜ ë³€ìˆ˜ í¬í•¨
            'Hematocrit_51221_merged',
            'Hemoglobin_51222',
            'Creatinine_50912_merged',
            'RDW_51277',
            'White_Blood_Cells_51301_merged',
            'Urea_Nitrogen_51006_merged',
            'Potassium_50971_merged',
            'Sodium_50983_merged',
            'Glucose_50931',
            # ì¶”ê°€ ë³€ìˆ˜ (30-70% ê²°ì¸¡)
            'Basophils_51146',            # 49.2% ê²°ì¸¡
            'Eosinophils_51200',          # 49.2% ê²°ì¸¡
            'PT_51274_merged',            # 49.2% ê²°ì¸¡
            'PTT_51275_merged',           # 50.1% ê²°ì¸¡
            'Calcium__Total_50893',       # 54.4% ê²°ì¸¡
            'Bilirubin__Total_50885',     # 64.8% ê²°ì¸¡
            'Lactate_50813_merged',       # 66.5% ê²°ì¸¡ (ì¤‘ì¦ë„ ì§€í‘œ)
            'Platelet_Count_51704'        # ì¶”ê°€ CBC í•­ëª©
        ],
        'clinical_relevance': 'CBC ìƒì„¸, ì‘ê³ ê²€ì‚¬, ê°„ê¸°ëŠ¥, ì¤‘ì¦ë„ ì§€í‘œ í¬í•¨'
    },
    
    'comprehensive': {
        'description': 'í¬ê´„ì  ë³€ìˆ˜ ì„¸íŠ¸ (ê²°ì¸¡ë¥  < 90%, ì¤‘ìš” ì§€í‘œ í¬í•¨)',
        'lab_features': [
            # í™•ì¥ ì„¸íŠ¸ í¬í•¨
            'Hematocrit_51221_merged',
            'Hemoglobin_51222',
            'Creatinine_50912_merged',
            'RDW_51277',
            'White_Blood_Cells_51301_merged',
            'Urea_Nitrogen_51006_merged',
            'Potassium_50971_merged',
            'Sodium_50983_merged',
            'Glucose_50931',
            'Basophils_51146',
            'Eosinophils_51200',
            'PT_51274_merged',
            'PTT_51275_merged',
            'Calcium__Total_50893',
            'Bilirubin__Total_50885',
            'Lactate_50813_merged',
            'Platelet_Count_51704',
            # ì¶”ê°€ ì¤‘ìš” ì§€í‘œ (70-90% ê²°ì¸¡)
            'Albumin_50862',              # 73.6% ê²°ì¸¡ (ì˜ì–‘ìƒíƒœ)
            'pH_50820',                   # 80.8% ê²°ì¸¡ (ì‚°ì—¼ê¸°)
            'pO2_50821_merged',           # 82.2% ê²°ì¸¡ (ì‚°ì†Œí™”)
            'pCO2_50818_merged',          # 82.3% ê²°ì¸¡ (í™˜ê¸°)
            'Creatine_Kinase_CK_50910',   # 82.8% ê²°ì¸¡ (ê·¼ìœ¡ì†ìƒ)
            'Troponin_T_51003',           # 87.0% ê²°ì¸¡ (ì‹¬ê·¼ì†ìƒ)
            'Chloride__Whole_Blood_50806_merged'  # ì „í•´ì§ˆ
        ],
        'clinical_relevance': 'ì¤‘ì¦ í™˜ì í‰ê°€ë¥¼ ìœ„í•œ íŠ¹ìˆ˜ ê²€ì‚¬ í¬í•¨'
    }
}

def load_full_dataset():
    """ì „ì²´ ë°ì´í„°ì…‹ ë¡œë“œ"""
    print("ì „ì²´ ë°ì´í„°ì…‹ ë¡œë”© ì¤‘...")
    df = pd.read_csv(DATA_DIR / 'prediction_dataset.csv')
    print(f"  - ë¡œë“œ ì™„ë£Œ: {len(df):,} x {len(df.columns):,}")
    return df

def calculate_missing_rates(df, lab_features):
    """ì„ íƒëœ ë³€ìˆ˜ë“¤ì˜ ê²°ì¸¡ë¥  ê³„ì‚°"""
    missing_rates = {}
    for col in lab_features:
        if col in df.columns:
            missing_rates[col] = df[col].isna().mean() * 100
    return missing_rates

def create_dataset_version(df, variable_set_name, variable_set_info):
    """íŠ¹ì • ë³€ìˆ˜ ì„¸íŠ¸ë¡œ ë°ì´í„°ì…‹ ìƒì„±"""
    print(f"\n{variable_set_name.upper()} ë°ì´í„°ì…‹ ìƒì„± ì¤‘...")
    print(f"  ì„¤ëª…: {variable_set_info['description']}")
    
    # í•„ìˆ˜ ì»¬ëŸ¼ (íƒ€ê²Ÿ, ì¸êµ¬í†µê³„)
    required_cols = [
        'hadm_id', 'subject_id',
        'death_type', 'death_binary', 'hospital_death',
        'los_hours', 'los_days',
        'age', 'gender', 'admission_type', 'hospital_expire_flag'
    ]
    
    # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” lab ë³€ìˆ˜ë§Œ ì„ íƒ
    available_lab_features = [col for col in variable_set_info['lab_features'] 
                              if col in df.columns]
    
    # ëˆ„ë½ëœ ë³€ìˆ˜ í™•ì¸
    missing_features = [col for col in variable_set_info['lab_features'] 
                        if col not in df.columns]
    
    if missing_features:
        print(f"  âš ï¸ ë°ì´í„°ì— ì—†ëŠ” ë³€ìˆ˜ {len(missing_features)}ê°œ:")
        for feat in missing_features[:5]:  # ì²˜ìŒ 5ê°œë§Œ í‘œì‹œ
            print(f"    - {feat}")
    
    # ìµœì¢… ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
    final_cols = required_cols + available_lab_features
    
    # ë°ì´í„°ì…‹ ìƒì„±
    df_subset = df[final_cols].copy()
    
    # ê²°ì¸¡ë¥  ê³„ì‚°
    missing_rates = calculate_missing_rates(df_subset, available_lab_features)
    
    # í†µê³„ ì •ë³´
    stats = {
        'dataset_type': variable_set_name,
        'description': variable_set_info['description'],
        'clinical_relevance': variable_set_info['clinical_relevance'],
        'n_samples': len(df_subset),
        'n_features': len(final_cols),
        'n_lab_features': len(available_lab_features),
        'n_demographic_features': len(required_cols) - 5,  # íƒ€ê²Ÿ ë³€ìˆ˜ ì œì™¸
        'missing_rates': {
            'mean': np.mean(list(missing_rates.values())),
            'median': np.median(list(missing_rates.values())),
            'max': np.max(list(missing_rates.values())),
            'min': np.min(list(missing_rates.values()))
        },
        'complete_cases': {
            'n_complete': df_subset.dropna().shape[0],
            'percent_complete': (df_subset.dropna().shape[0] / len(df_subset)) * 100
        },
        'lab_features': available_lab_features,
        'missing_features': missing_features
    }
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"  - Lab ë³€ìˆ˜: {len(available_lab_features)}ê°œ")
    print(f"  - í‰ê·  ê²°ì¸¡ë¥ : {stats['missing_rates']['mean']:.1f}%")
    print(f"  - ì™„ì „í•œ ì¼€ì´ìŠ¤: {stats['complete_cases']['n_complete']:,}ê°œ ({stats['complete_cases']['percent_complete']:.1f}%)")
    
    return df_subset, stats

def create_missing_indicator_features(df, lab_features):
    """ê²°ì¸¡ ì§€ì‹œì ë³€ìˆ˜ ìƒì„±"""
    df_with_indicators = df.copy()
    
    for col in lab_features:
        if col in df.columns:
            # ê²°ì¸¡ ì—¬ë¶€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì´ì§„ ë³€ìˆ˜ ìƒì„±
            df_with_indicators[f'{col}_missing'] = df[col].isna().astype(int)
    
    return df_with_indicators

def visualize_dataset_comparison(all_stats):
    """ë°ì´í„°ì…‹ ë¹„êµ ì‹œê°í™”"""
    print("\nì‹œê°í™” ìƒì„± ì¤‘...")
    
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    
    # 1. ë³€ìˆ˜ ìˆ˜ ë¹„êµ
    datasets = list(all_stats.keys())
    n_features = [stats['n_lab_features'] for stats in all_stats.values()]
    
    axes[0, 0].bar(datasets, n_features, color=['#3498db', '#e74c3c', '#2ecc71'])
    axes[0, 0].set_title('ë°ì´í„°ì…‹ë³„ Lab ë³€ìˆ˜ ìˆ˜', fontsize=12, fontweight='bold')
    axes[0, 0].set_ylabel('ë³€ìˆ˜ ìˆ˜')
    for i, v in enumerate(n_features):
        axes[0, 0].text(i, v + 0.5, str(v), ha='center')
    
    # 2. í‰ê·  ê²°ì¸¡ë¥  ë¹„êµ
    missing_rates = [stats['missing_rates']['mean'] for stats in all_stats.values()]
    
    axes[0, 1].bar(datasets, missing_rates, color=['#3498db', '#e74c3c', '#2ecc71'])
    axes[0, 1].set_title('ë°ì´í„°ì…‹ë³„ í‰ê·  ê²°ì¸¡ë¥ ', fontsize=12, fontweight='bold')
    axes[0, 1].set_ylabel('ê²°ì¸¡ë¥  (%)')
    for i, v in enumerate(missing_rates):
        axes[0, 1].text(i, v + 1, f'{v:.1f}%', ha='center')
    
    # 3. ì™„ì „í•œ ì¼€ì´ìŠ¤ ë¹„êµ
    complete_cases = [stats['complete_cases']['n_complete'] for stats in all_stats.values()]
    
    axes[1, 0].bar(datasets, complete_cases, color=['#3498db', '#e74c3c', '#2ecc71'])
    axes[1, 0].set_title('ì™„ì „í•œ ì¼€ì´ìŠ¤ ìˆ˜', fontsize=12, fontweight='bold')
    axes[1, 0].set_ylabel('ì¼€ì´ìŠ¤ ìˆ˜')
    for i, v in enumerate(complete_cases):
        axes[1, 0].text(i, v + 10, str(v), ha='center')
    
    # 4. ë°ì´í„°ì…‹ ìš”ì•½ í…Œì´ë¸”
    axes[1, 1].axis('off')
    table_data = []
    for name, stats in all_stats.items():
        table_data.append([
            name.capitalize(),
            f"{stats['n_lab_features']}",
            f"{stats['missing_rates']['mean']:.1f}%",
            f"{stats['complete_cases']['percent_complete']:.1f}%"
        ])
    
    table = axes[1, 1].table(cellText=table_data,
                            colLabels=['ë°ì´í„°ì…‹', 'Lab ë³€ìˆ˜', 'í‰ê·  ê²°ì¸¡ë¥ ', 'ì™„ì „ ì¼€ì´ìŠ¤'],
                            cellLoc='center',
                            loc='center',
                            colWidths=[0.25, 0.2, 0.25, 0.25])
    table.auto_set_font_size(False)
    table.set_fontsize(10)
    table.scale(1.2, 1.5)
    
    # í—¤ë” ìŠ¤íƒ€ì¼
    for (i, j), cell in table.get_celld().items():
        if i == 0:
            cell.set_facecolor('#34495e')
            cell.set_text_props(weight='bold', color='white')
    
    plt.suptitle('ì˜ˆì¸¡ ëª¨ë¸ìš© ë°ì´í„°ì…‹ ë¹„êµ', fontsize=14, fontweight='bold', y=1.02)
    plt.tight_layout()
    plt.savefig(FIGURES_DIR / 'dataset_comparison.png', dpi=300, bbox_inches='tight')
    print("  - ë°ì´í„°ì…‹ ë¹„êµ ì‹œê°í™” ì €ì¥: dataset_comparison.png")
    
    plt.close()

def save_datasets(datasets_dict):
    """ë°ì´í„°ì…‹ ì €ì¥"""
    print("\në°ì´í„°ì…‹ ì €ì¥ ì¤‘...")
    
    for name, (df, stats) in datasets_dict.items():
        # CSV ì €ì¥
        output_path = OUTPUT_DIR / f'model_dataset_{name}.csv'
        df.to_csv(output_path, index=False)
        print(f"  - {name}: {output_path}")
        
        # í†µê³„ ì •ë³´ JSON ì €ì¥
        stats_path = OUTPUT_DIR / f'model_dataset_{name}_stats.json'
        with open(stats_path, 'w', encoding='utf-8') as f:
            # numpy íƒ€ì…ì„ Python íƒ€ì…ìœ¼ë¡œ ë³€í™˜
            stats_serializable = json.loads(json.dumps(stats, default=lambda x: float(x) if isinstance(x, np.floating) else x))
            json.dump(stats_serializable, f, indent=2, ensure_ascii=False)
        
        # Missing indicator ë²„ì „ë„ ìƒì„±
        if name != 'comprehensive':  # comprehensiveëŠ” ë„ˆë¬´ ë§ì•„ì„œ ì œì™¸
            lab_features = [col for col in df.columns 
                          if col not in ['hadm_id', 'subject_id', 'death_type', 'death_binary', 
                                       'hospital_death', 'los_hours', 'los_days', 'age', 
                                       'gender', 'admission_type', 'hospital_expire_flag']]
            
            df_with_indicators = create_missing_indicator_features(df, lab_features)
            indicator_path = OUTPUT_DIR / f'model_dataset_{name}_with_indicators.csv'
            df_with_indicators.to_csv(indicator_path, index=False)
            print(f"    + Missing indicators: {indicator_path}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 80)
    print("ì˜ˆì¸¡ ëª¨ë¸ìš© ë°ì´í„°ì…‹ ìƒì„±")
    print("=" * 80)
    
    # ì „ì²´ ë°ì´í„° ë¡œë“œ
    df = load_full_dataset()
    
    # ê° ë³€ìˆ˜ ì„¸íŠ¸ë³„ë¡œ ë°ì´í„°ì…‹ ìƒì„±
    datasets = {}
    all_stats = {}
    
    for set_name, set_info in VARIABLE_SETS.items():
        df_subset, stats = create_dataset_version(df, set_name, set_info)
        datasets[set_name] = (df_subset, stats)
        all_stats[set_name] = stats
    
    # ì‹œê°í™”
    visualize_dataset_comparison(all_stats)
    
    # ì €ì¥
    save_datasets(datasets)
    
    # ìµœì¢… ìš”ì•½
    print("\n" + "=" * 80)
    print("ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ ìš”ì•½")
    print("=" * 80)
    
    print("\nğŸ“Š ìƒì„±ëœ ë°ì´í„°ì…‹:")
    for name, stats in all_stats.items():
        print(f"\n{name.upper()}:")
        print(f"  - ì„¤ëª…: {stats['description']}")
        print(f"  - í¬ê¸°: {stats['n_samples']:,} x {stats['n_features']}")
        print(f"  - Lab ë³€ìˆ˜: {stats['n_lab_features']}ê°œ")
        print(f"  - í‰ê·  ê²°ì¸¡ë¥ : {stats['missing_rates']['mean']:.1f}%")
        print(f"  - ì™„ì „ ì¼€ì´ìŠ¤: {stats['complete_cases']['n_complete']:,}ê°œ")
    
    print("\nğŸ’¡ ëª¨ë¸ë§ ê¶Œì¥ì‚¬í•­:")
    print("1. ESSENTIAL: ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘, ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸")
    print("2. EXTENDED: ì‹¤ìš©ì  ëª¨ë¸, ê· í˜•ì¡íŒ ì„±ëŠ¥")
    print("3. COMPREHENSIVE: ê³ ê¸‰ ëª¨ë¸, ê²°ì¸¡ê°’ ì²˜ë¦¬ í•„ìˆ˜")
    
    print("\nâœ… ëª¨ë“  ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ!")

if __name__ == "__main__":
    main()