#!/usr/bin/env python3
"""
ë¼ë²¨ ê¸°ë°˜ ì»¤ë²„ë¦¬ì§€ ë¶„ì„
- itemidë³„ì´ ì•„ë‹Œ ë¼ë²¨ë³„ë¡œ ë°ì´í„° í†µí•©í•˜ì—¬ ë¶„ì„
- ì‹¤ì œë¡œ ë¹„ì–´ìˆëŠ” í•­ëª© vs itemid ë¬¸ì œë¡œ ë¹„ì–´ë³´ì´ëŠ” í•­ëª© êµ¬ë¶„
- ë°ì´í„°ëŠ” ìˆ˜ì •í•˜ì§€ ì•Šê³  ë¶„ì„ë§Œ ìˆ˜í–‰
"""

import pandas as pd
import numpy as np
import json
import os
import matplotlib.pyplot as plt
import seaborn as sns
import platform

# í•œê¸€ í°íŠ¸ ì„¤ì •
if platform.system() == 'Darwin':
    plt.rcParams['font.family'] = 'AppleGothic'
elif platform.system() == 'Windows':
    plt.rcParams['font.family'] = 'Malgun Gothic'
else:
    plt.rcParams['font.family'] = 'NanumGothic'
plt.rcParams['axes.unicode_minus'] = False

# ê²½ë¡œ ì„¤ì •
BASE_PATH = '/Users/hyungjun/Desktop/fast campus_lecture/analysis_initial_lab_re'
DATA_PATH = os.path.join(BASE_PATH, 'data')
FIGURE_PATH = os.path.join(BASE_PATH, 'figures')

os.makedirs(FIGURE_PATH, exist_ok=True)

def load_data():
    """ë°ì´í„° ë¡œë“œ"""
    print("ë°ì´í„° ë¡œë”© ì¤‘...")
    
    # ê²€ì‚¬ í•­ëª© ìš”ì•½
    items_df = pd.read_csv(os.path.join(DATA_PATH, 'lab_items_summary.csv'))
    
    # offset ì •ë³´ (ì‹¤ì œ ì¸¡ì • ë°ì´í„°)
    offset_df = pd.read_csv(os.path.join(DATA_PATH, 'labs_offset_info.csv'))
    
    # ë¹ˆ ì»¬ëŸ¼ ìƒì„¸
    empty_df = pd.read_csv(os.path.join(DATA_PATH, 'empty_columns_details.csv'))
    
    # ëŒ€ì²´ itemid
    alt_df = pd.read_csv(os.path.join(DATA_PATH, 'alternative_itemids.csv'))
    
    print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
    
    return items_df, offset_df, empty_df, alt_df

def analyze_itemid_vs_label(items_df):
    """itemidë³„ ë¶„ì„ vs ë¼ë²¨ë³„ ë¶„ì„ ë¹„êµ"""
    print("\n" + "="*70)
    print("1. ItemIDë³„ vs ë¼ë²¨ë³„ í˜„í™© ë¹„êµ")
    print("="*70)
    
    # í˜„ì¬ ìƒíƒœ (itemidë³„)
    total_itemids = len(items_df)
    active_itemids = len(items_df[items_df['has_data'] == True])
    empty_itemids = len(items_df[items_df['has_data'] == False])
    
    print(f"\nğŸ“Š í˜„ì¬ ìƒíƒœ (ItemID ê¸°ì¤€):")
    print(f"   - ì „ì²´ itemid: {total_itemids}ê°œ")
    print(f"   - ë°ì´í„° ìˆëŠ” itemid: {active_itemids}ê°œ ({active_itemids/total_itemids*100:.1f}%)")
    print(f"   - ë¹ˆ itemid: {empty_itemids}ê°œ ({empty_itemids/total_itemids*100:.1f}%)")
    
    # ë¼ë²¨ë³„ ê·¸ë£¹í™”
    label_groups = items_df.groupby('original_label').agg({
        'itemid': 'count',
        'data_count': 'sum',
        'has_data': 'any'
    }).rename(columns={'itemid': 'itemid_count', 'has_data': 'label_has_data'})
    
    total_labels = len(label_groups)
    active_labels = len(label_groups[label_groups['label_has_data'] == True])
    empty_labels = len(label_groups[label_groups['label_has_data'] == False])
    
    print(f"\nğŸ“Š ë¼ë²¨ ê¸°ì¤€ ë¶„ì„:")
    print(f"   - ê³ ìœ  ë¼ë²¨: {total_labels}ê°œ")
    print(f"   - ë°ì´í„° ìˆëŠ” ë¼ë²¨: {active_labels}ê°œ ({active_labels/total_labels*100:.1f}%)")
    print(f"   - ë¹ˆ ë¼ë²¨: {empty_labels}ê°œ ({empty_labels/total_labels*100:.1f}%)")
    
    # ê°œì„  ê°€ëŠ¥ì„±
    improvement_potential = active_labels - active_itemids
    print(f"\nğŸ’¡ ê°œì„  ê°€ëŠ¥ì„±:")
    print(f"   - itemid í†µí•© ì‹œ ì¶”ê°€ í™œì„±í™” ê°€ëŠ¥: {empty_itemids - empty_labels}ê°œ")
    print(f"   - ì‹¤ì œë¡œ ì™„ì „íˆ ë¹„ì–´ìˆëŠ” í•­ëª©: {empty_labels}ê°œ (ë¼ë²¨ ê¸°ì¤€)")
    
    return label_groups

def analyze_duplicate_labels(items_df, label_groups):
    """ì¤‘ë³µ ë¼ë²¨ ìƒì„¸ ë¶„ì„"""
    print("\n" + "="*70)
    print("2. ì¤‘ë³µ ë¼ë²¨ ìƒì„¸ ë¶„ì„")
    print("="*70)
    
    # ì—¬ëŸ¬ itemidë¥¼ ê°€ì§„ ë¼ë²¨
    duplicate_labels = label_groups[label_groups['itemid_count'] > 1].copy()
    duplicate_labels = duplicate_labels.sort_values('itemid_count', ascending=False)
    
    print(f"\nğŸ“Š ì¤‘ë³µ ë¼ë²¨ í˜„í™©: {len(duplicate_labels)}ê°œ ë¼ë²¨ì´ ì—¬ëŸ¬ itemid ë³´ìœ ")
    
    # ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
    categories = {
        'all_empty': [],      # ëª¨ë“  itemidê°€ ë¹„ì–´ìˆìŒ
        'partial_data': [],   # ì¼ë¶€ itemidì—ë§Œ ë°ì´í„° ìˆìŒ
        'all_active': []      # ëª¨ë“  itemidì— ë°ì´í„° ìˆìŒ (ë“œë¬¼ ê²ƒ)
    }
    
    for label, group_data in duplicate_labels.iterrows():
        # í•´ë‹¹ ë¼ë²¨ì˜ ëª¨ë“  itemid ì •ë³´
        label_items = items_df[items_df['original_label'] == label]
        
        has_data_count = label_items['has_data'].sum()
        total_count = len(label_items)
        total_data = label_items['data_count'].sum()
        
        if has_data_count == 0:
            categories['all_empty'].append({
                'label': label,
                'itemid_count': total_count,
                'itemids': label_items['itemid'].tolist()
            })
        elif has_data_count == total_count:
            categories['all_active'].append({
                'label': label,
                'itemid_count': total_count,
                'total_data': total_data,
                'itemids': label_items['itemid'].tolist()
            })
        else:
            categories['partial_data'].append({
                'label': label,
                'empty_itemids': label_items[label_items['has_data'] == False]['itemid'].tolist(),
                'active_itemids': label_items[label_items['has_data'] == True]['itemid'].tolist(),
                'total_data': total_data,
                'potential_loss': f"{has_data_count}/{total_count} active"
            })
    
    print(f"\nğŸ“Š ì¤‘ë³µ ë¼ë²¨ ë¶„ë¥˜:")
    print(f"   - ì¼ë¶€ë§Œ ë°ì´í„° ìˆìŒ: {len(categories['partial_data'])}ê°œ")
    print(f"   - ëª¨ë‘ ë¹„ì–´ìˆìŒ: {len(categories['all_empty'])}ê°œ")
    print(f"   - ëª¨ë‘ í™œì„±: {len(categories['all_active'])}ê°œ")
    
    # ìƒì„¸ ì¶œë ¥
    if categories['partial_data']:
        print(f"\nâš ï¸ ItemID ë¬¸ì œë¡œ ë°ì´í„° ì†ì‹¤ ì¤‘ì¸ ë¼ë²¨ (Top 10):")
        for item in categories['partial_data'][:10]:
            print(f"   - {item['label']}: "
                  f"ë¹ˆ itemid {item['empty_itemids']} â†’ "
                  f"í™œì„± itemid {item['active_itemids']}")
            print(f"     (ì´ {item['total_data']}ê±´ ë°ì´í„° ì¡´ì¬)")
    
    return categories

def analyze_itemid_patterns(items_df, offset_df):
    """ItemID ë²ˆí˜¸ íŒ¨í„´ ë¶„ì„"""
    print("\n" + "="*70)
    print("3. ItemID ë²ˆí˜¸ íŒ¨í„´ ë¶„ì„")
    print("="*70)
    
    # itemid ë²ˆí˜¸ëŒ€ë³„ ë¶„ë¥˜
    def classify_itemid(itemid):
        if itemid < 51000:
            return '50000ëŒ€ (êµ¬í˜•)'
        elif itemid < 52000:
            return '51000ëŒ€ (í˜„ì¬)'
        else:
            return '52000ëŒ€ (ì‹ í˜•)'
    
    items_df['itemid_range'] = items_df['itemid'].apply(classify_itemid)
    
    # ë²ˆí˜¸ëŒ€ë³„ í†µê³„
    range_stats = items_df.groupby('itemid_range').agg({
        'itemid': 'count',
        'has_data': 'sum',
        'data_count': 'sum'
    }).rename(columns={'itemid': 'total_items', 'has_data': 'active_items'})
    
    print("\nğŸ“Š ItemID ë²ˆí˜¸ëŒ€ë³„ ë¶„í¬:")
    for range_name, stats in range_stats.iterrows():
        active_pct = stats['active_items'] / stats['total_items'] * 100
        print(f"   - {range_name}: {stats['total_items']}ê°œ "
              f"(í™œì„± {stats['active_items']}ê°œ, {active_pct:.1f}%)")
        if stats['data_count'] > 0:
            print(f"     ë°ì´í„°: {stats['data_count']:.0f}ê±´")
    
    # ì‹¤ì œ ì‚¬ìš© íŒ¨í„´ (offset_df ê¸°ë°˜)
    offset_itemid_counts = offset_df['itemid'].value_counts()
    
    # ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ëŠ” itemid Top 10
    print("\nğŸ“Š ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ëŠ” ItemID Top 10:")
    for itemid, count in offset_itemid_counts.head(10).items():
        item_info = items_df[items_df['itemid'] == itemid]
        if not item_info.empty:
            label = item_info.iloc[0]['original_label']
            range_class = classify_itemid(itemid)
            print(f"   - {itemid} ({range_class}): {label} - {count}ê±´")
    
    return range_stats

def find_real_empty_labels(label_groups, items_df):
    """ì‹¤ì œë¡œ ì™„ì „íˆ ë¹„ì–´ìˆëŠ” ë¼ë²¨ ì°¾ê¸°"""
    print("\n" + "="*70)
    print("4. ì‹¤ì œë¡œ ì™„ì „íˆ ë¹„ì–´ìˆëŠ” ê²€ì‚¬ í•­ëª©")
    print("="*70)
    
    # ë°ì´í„°ê°€ ì „í˜€ ì—†ëŠ” ë¼ë²¨
    empty_labels = label_groups[label_groups['label_has_data'] == False]
    
    print(f"\nğŸ“Š ì™„ì „íˆ ë¹„ì–´ìˆëŠ” ë¼ë²¨: {len(empty_labels)}ê°œ")
    
    # ì›ì¸ë³„ ë¶„ë¥˜
    real_empty = {
        'special_tests': [],
        'blood_gas': [],
        'other_fluid': [],
        'unknown': []
    }
    
    for label, _ in empty_labels.iterrows():
        # í•´ë‹¹ ë¼ë²¨ì˜ ëª¨ë“  itemid
        label_items = items_df[items_df['original_label'] == label]
        
        # ì¹´í…Œê³ ë¦¬ í™•ì¸
        categories = label_items['category'].unique()
        fluids = label_items['fluid'].unique()
        
        # ë¶„ë¥˜
        if 'COVID' in label or 'CA 19-9' in label or 'INR' in label:
            real_empty['special_tests'].append(label)
        elif 'Blood Gas' in str(categories[0]):
            real_empty['blood_gas'].append(label)
        elif 'Other Body Fluid' in str(fluids[0]) or 'Fluid' in str(fluids[0]):
            real_empty['other_fluid'].append(label)
        else:
            real_empty['unknown'].append(label)
    
    print("\nğŸ“Š ì‹¤ì œ ë¹ˆ ë¼ë²¨ ì›ì¸:")
    print(f"   - íŠ¹ìˆ˜ ê²€ì‚¬: {len(real_empty['special_tests'])}ê°œ")
    if real_empty['special_tests']:
        for test in real_empty['special_tests'][:5]:
            print(f"     â€¢ {test}")
    
    print(f"\n   - Blood Gas ê´€ë ¨: {len(real_empty['blood_gas'])}ê°œ")
    if real_empty['blood_gas']:
        for test in real_empty['blood_gas'][:5]:
            print(f"     â€¢ {test}")
    
    print(f"\n   - ê¸°íƒ€ ì²´ì•¡: {len(real_empty['other_fluid'])}ê°œ")
    if real_empty['other_fluid']:
        for test in real_empty['other_fluid'][:5]:
            print(f"     â€¢ {test}")
    
    print(f"\n   - ì›ì¸ ë¶ˆëª…: {len(real_empty['unknown'])}ê°œ")
    
    return real_empty

def create_analysis_visualizations(items_df, label_groups, range_stats, categories):
    """ë¶„ì„ ì‹œê°í™”"""
    print("\n" + "="*70)
    print("5. ì‹œê°í™” ìƒì„±")
    print("="*70)
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    
    # 1. ItemID vs ë¼ë²¨ ê¸°ì¤€ ë¹„êµ
    ax1 = axes[0, 0]
    comparison_data = {
        'ItemID ê¸°ì¤€': [48, 39],  # í™œì„±, ë¹„í™œì„±
        'ë¼ë²¨ ê¸°ì¤€': [
            len(label_groups[label_groups['label_has_data'] == True]),
            len(label_groups[label_groups['label_has_data'] == False])
        ]
    }
    
    x = np.arange(len(['í™œì„±', 'ë¹„í™œì„±']))
    width = 0.35
    
    for i, (key, values) in enumerate(comparison_data.items()):
        ax1.bar(x + i*width, values, width, label=key)
    
    ax1.set_xlabel('ìƒíƒœ')
    ax1.set_ylabel('ê°œìˆ˜')
    ax1.set_title('ItemIDë³„ vs ë¼ë²¨ë³„ ì»¤ë²„ë¦¬ì§€ ë¹„êµ')
    ax1.set_xticks(x + width/2)
    ax1.set_xticklabels(['í™œì„±', 'ë¹„í™œì„±'])
    ax1.legend()
    
    # ê°’ í‘œì‹œ
    for i, (key, values) in enumerate(comparison_data.items()):
        for j, v in enumerate(values):
            ax1.text(j + i*width, v, str(v), ha='center', va='bottom')
    
    # 2. ItemID ë²ˆí˜¸ëŒ€ë³„ í™œì„±ë¥ 
    ax2 = axes[0, 1]
    range_names = range_stats.index
    active_pcts = (range_stats['active_items'] / range_stats['total_items'] * 100).values
    
    bars = ax2.bar(range(len(range_names)), active_pcts, 
                   color=['#ff9999', '#66b3ff', '#99ff99'])
    ax2.set_xticks(range(len(range_names)))
    ax2.set_xticklabels(range_names, rotation=45, ha='right')
    ax2.set_ylabel('í™œì„± ë¹„ìœ¨ (%)')
    ax2.set_title('ItemID ë²ˆí˜¸ëŒ€ë³„ ë°ì´í„° í™œì„±ë¥ ')
    ax2.set_ylim(0, 100)
    
    # ê°’ í‘œì‹œ
    for bar, pct in zip(bars, active_pcts):
        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height(),
                f'{pct:.1f}%', ha='center', va='bottom')
    
    # 3. ì¤‘ë³µ ë¼ë²¨ ë¶„ë¥˜
    ax3 = axes[1, 0]
    dup_categories = {
        'ì¼ë¶€ í™œì„±': len(categories['partial_data']),
        'ëª¨ë‘ ë¹„í™œì„±': len(categories['all_empty']),
        'ëª¨ë‘ í™œì„±': len(categories['all_active'])
    }
    
    colors = ['#ffd700', '#ff6b6b', '#4ecdc4']
    wedges, texts, autotexts = ax3.pie(dup_categories.values(), 
                                        labels=dup_categories.keys(),
                                        colors=colors,
                                        autopct=lambda pct: f'{int(pct*sum(dup_categories.values())/100)}ê°œ\n({pct:.1f}%)',
                                        startangle=90)
    ax3.set_title('ì¤‘ë³µ ë¼ë²¨ ë°ì´í„° ìƒíƒœ ë¶„í¬')
    
    # 4. ê°œì„  ê°€ëŠ¥ì„±
    ax4 = axes[1, 1]
    
    # í˜„ì¬ vs ê°œì„  í›„
    current_active = len(items_df[items_df['has_data'] == True])
    label_based_active = len(label_groups[label_groups['label_has_data'] == True])
    
    improvement_data = {
        'í˜„ì¬\n(ItemIDë³„)': [current_active, 87-current_active],
        'ë¼ë²¨ í†µí•© ì‹œ': [label_based_active, len(label_groups)-label_based_active]
    }
    
    x_pos = np.arange(len(improvement_data))
    bottoms = [0, 0]
    colors_stack = ['#2ca02c', '#ff7f0e']
    labels = ['í™œì„±', 'ë¹„í™œì„±']
    
    for i, label in enumerate(labels):
        values = [improvement_data[k][i] for k in improvement_data.keys()]
        bars = ax4.bar(x_pos, values, bottom=bottoms, 
                      label=label, color=colors_stack[i])
        
        # ê°’ í‘œì‹œ
        for j, (v, b) in enumerate(zip(values, bottoms)):
            if v > 0:
                ax4.text(j, b + v/2, f'{v}', ha='center', va='center', fontweight='bold')
        
        bottoms = [b + v for b, v in zip(bottoms, values)]
    
    ax4.set_xticks(x_pos)
    ax4.set_xticklabels(improvement_data.keys())
    ax4.set_ylabel('ê²€ì‚¬ í•­ëª© ìˆ˜')
    ax4.set_title('ë¼ë²¨ í†µí•© ì‹œ ê°œì„  íš¨ê³¼')
    ax4.legend()
    ax4.set_ylim(0, 90)
    
    plt.tight_layout()
    plt.savefig(os.path.join(FIGURE_PATH, 'label_based_analysis.png'), 
                dpi=150, bbox_inches='tight')
    print(f"âœ… ì‹œê°í™” ì €ì¥: label_based_analysis.png")
    
    plt.close()

def save_analysis_results(label_groups, categories, real_empty):
    """ë¶„ì„ ê²°ê³¼ ì €ì¥"""
    print("\n" + "="*70)
    print("6. ë¶„ì„ ê²°ê³¼ ì €ì¥")
    print("="*70)
    
    # ë¼ë²¨ë³„ í†µê³„ ì €ì¥
    label_stats = label_groups.reset_index()
    label_stats.to_csv(os.path.join(DATA_PATH, 'label_based_statistics.csv'), index=False)
    
    # ê°œì„  ê°€ëŠ¥ í•­ëª© ì €ì¥
    improvable_items = []
    for item in categories['partial_data']:
        improvable_items.append({
            'label': item['label'],
            'empty_itemids': ';'.join(map(str, item['empty_itemids'])),
            'active_itemids': ';'.join(map(str, item['active_itemids'])),
            'total_data': item['total_data']
        })
    
    if improvable_items:
        improvable_df = pd.DataFrame(improvable_items)
        improvable_df.to_csv(os.path.join(DATA_PATH, 'improvable_items.csv'), index=False)
    
    # ë¶„ì„ ìš”ì•½ JSON
    summary = {
        'analysis_type': 'label_based_coverage',
        'itemid_analysis': {
            'total': 87,
            'active': 48,
            'empty': 39,
            'coverage_pct': 55.2
        },
        'label_analysis': {
            'total': len(label_groups),
            'active': len(label_groups[label_groups['label_has_data'] == True]),
            'empty': len(label_groups[label_groups['label_has_data'] == False]),
            'coverage_pct': len(label_groups[label_groups['label_has_data'] == True]) / len(label_groups) * 100
        },
        'duplicate_labels': {
            'total': len(label_groups[label_groups['itemid_count'] > 1]),
            'partial_data': len(categories['partial_data']),
            'all_empty': len(categories['all_empty']),
            'all_active': len(categories['all_active'])
        },
        'real_empty': {
            'total': len(label_groups[label_groups['label_has_data'] == False]),
            'special_tests': len(real_empty['special_tests']),
            'blood_gas': len(real_empty['blood_gas']),
            'other_fluid': len(real_empty['other_fluid']),
            'unknown': len(real_empty['unknown'])
        },
        'improvement_potential': {
            'false_empty_itemids': 39 - len(label_groups[label_groups['label_has_data'] == False]),
            'description': 'ItemID í†µí•© ì‹œ í™œì„±í™” ê°€ëŠ¥í•œ í•­ëª© ìˆ˜'
        }
    }
    
    with open(os.path.join(DATA_PATH, 'label_analysis_summary.json'), 'w') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… ê²°ê³¼ íŒŒì¼ ì €ì¥ ì™„ë£Œ")
    print(f"   - label_based_statistics.csv")
    print(f"   - improvable_items.csv")
    print(f"   - label_analysis_summary.json")
    
    return summary

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("\n" + "ğŸ”¬ " * 20)
    print(" ë¼ë²¨ ê¸°ë°˜ ì»¤ë²„ë¦¬ì§€ ë¶„ì„ (ì˜¤ë¥˜ ë¶„ì„)")
    print("ğŸ”¬ " * 20)
    
    # ë°ì´í„° ë¡œë“œ
    items_df, offset_df, empty_df, alt_df = load_data()
    
    # ItemID vs ë¼ë²¨ ë¶„ì„
    label_groups = analyze_itemid_vs_label(items_df)
    
    # ì¤‘ë³µ ë¼ë²¨ ë¶„ì„
    categories = analyze_duplicate_labels(items_df, label_groups)
    
    # ItemID íŒ¨í„´ ë¶„ì„
    range_stats = analyze_itemid_patterns(items_df, offset_df)
    
    # ì‹¤ì œ ë¹ˆ ë¼ë²¨ ì°¾ê¸°
    real_empty = find_real_empty_labels(label_groups, items_df)
    
    # ì‹œê°í™”
    create_analysis_visualizations(items_df, label_groups, range_stats, categories)
    
    # ê²°ê³¼ ì €ì¥
    summary = save_analysis_results(label_groups, categories, real_empty)
    
    print("\n" + "="*70)
    print("âœ… ë¼ë²¨ ê¸°ë°˜ ë¶„ì„ ì™„ë£Œ!")
    print("="*70)
    print(f"\nğŸ“Š í•µì‹¬ ë°œê²¬:")
    print(f"   - ItemID ê¸°ì¤€: 87ê°œ ì¤‘ 48ê°œ í™œì„± (55.2%)")
    print(f"   - ë¼ë²¨ ê¸°ì¤€: {summary['label_analysis']['total']}ê°œ ì¤‘ "
          f"{summary['label_analysis']['active']}ê°œ í™œì„± ({summary['label_analysis']['coverage_pct']:.1f}%)")
    print(f"   - ê±°ì§“ ë¹ˆ í•­ëª©: {summary['improvement_potential']['false_empty_itemids']}ê°œ "
          f"(itemid ë¬¸ì œ)")
    print(f"   - ì§„ì§œ ë¹ˆ í•­ëª©: {summary['real_empty']['total']}ê°œ (ë¼ë²¨ ê¸°ì¤€)")

if __name__ == "__main__":
    main()