#!/usr/bin/env python3
"""
ê°™ì€ ë¼ë²¨ì˜ ì—¬ëŸ¬ itemidê°€ ëª¨ë‘ í™œì„±ì¸ ê²½ìš° ë¶„ì„
- ì‹¤ì œë¡œ ê°’ì´ ë‹¤ë¥¸ì§€ í™•ì¸
- ì¤‘ë³µ ì¸¡ì •ì¸ì§€, ë‹¤ë¥¸ ì¸¡ì • ë°©ë²•ì¸ì§€ ë¶„ì„
"""

import pandas as pd
import numpy as np
import json
import os
import matplotlib.pyplot as plt
import seaborn as sns
import platform

# í•œê¸€ í°íŠ¸ ì„¤ì •
if platform.system() == 'Darwin':
    plt.rcParams['font.family'] = 'AppleGothic'
elif platform.system() == 'Windows':
    plt.rcParams['font.family'] = 'Malgun Gothic'
else:
    plt.rcParams['font.family'] = 'NanumGothic'
plt.rcParams['axes.unicode_minus'] = False

# ê²½ë¡œ ì„¤ì •
BASE_PATH = '/Users/hyungjun/Desktop/fast campus_lecture'
OUTPUT_PATH = os.path.join(BASE_PATH, 'analysis_initial_lab_re')
DATA_PATH = os.path.join(OUTPUT_PATH, 'data')
FIGURE_PATH = os.path.join(OUTPUT_PATH, 'figures')

os.makedirs(FIGURE_PATH, exist_ok=True)

def load_data():
    """ë°ì´í„° ë¡œë“œ"""
    print("ë°ì´í„° ë¡œë”© ì¤‘...")
    
    # ê²€ì‚¬ í•­ëª© ìš”ì•½
    items_df = pd.read_csv(os.path.join(DATA_PATH, 'lab_items_summary.csv'))
    
    # Long format ë°ì´í„° (ì‹¤ì œ ì¸¡ì •ê°’)
    labs_long = pd.read_csv(os.path.join(DATA_PATH, 'labs_initial_long.csv'))
    
    # ì›ë³¸ labevents (ë” ë§ì€ ë°ì´í„°)
    labevents = pd.read_csv(os.path.join(BASE_PATH, 'processed_data/hosp/labevents_sampled.csv'))
    
    print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
    print(f"   - ê²€ì‚¬ í•­ëª©: {len(items_df)}ê°œ")
    print(f"   - ì¶”ì¶œëœ ê²€ì‚¬: {len(labs_long):,}ê±´")
    print(f"   - ì „ì²´ ê²€ì‚¬: {len(labevents):,}ê±´")
    
    return items_df, labs_long, labevents

def find_duplicate_active_labels(items_df):
    """ê°™ì€ ë¼ë²¨ì— ì—¬ëŸ¬ í™œì„± itemidê°€ ìˆëŠ” ê²½ìš° ì°¾ê¸°"""
    print("\n" + "="*70)
    print("1. ì¤‘ë³µ í™œì„± ë¼ë²¨ ì°¾ê¸°")
    print("="*70)
    
    # ë°ì´í„°ê°€ ìˆëŠ” í•­ëª©ë§Œ
    active_items = items_df[items_df['has_data'] == True].copy()
    
    # ë¼ë²¨ë³„ë¡œ ê·¸ë£¹í™”
    label_groups = active_items.groupby('original_label').agg({
        'itemid': list,
        'data_count': list,
        'coverage_pct': list
    })
    
    # ì—¬ëŸ¬ itemidë¥¼ ê°€ì§„ ë¼ë²¨
    duplicate_active = label_groups[label_groups['itemid'].apply(len) > 1].copy()
    
    print(f"\nğŸ“Š ê°™ì€ ë¼ë²¨ì— ì—¬ëŸ¬ í™œì„± itemidê°€ ìˆëŠ” ê²½ìš°: {len(duplicate_active)}ê°œ")
    
    if len(duplicate_active) > 0:
        print("\në¼ë²¨ë³„ í™œì„± itemid í˜„í™©:")
        for label, row in duplicate_active.iterrows():
            itemids = row['itemid']
            counts = row['data_count']
            coverages = row['coverage_pct']
            
            print(f"\nğŸ“Œ {label}:")
            for itemid, count, coverage in zip(itemids, counts, coverages):
                print(f"   - itemid {itemid}: {count}ê±´ ({coverage:.1f}%)")
    
    return duplicate_active

def analyze_value_differences(duplicate_active, labs_long, labevents):
    """ê°™ì€ ë¼ë²¨ì˜ ë‹¤ë¥¸ itemidë“¤ ê°„ ê°’ ì°¨ì´ ë¶„ì„"""
    print("\n" + "="*70)
    print("2. ê°’ ì°¨ì´ ë¶„ì„")
    print("="*70)
    
    analysis_results = []
    
    for label, row in duplicate_active.iterrows():
        itemids = row['itemid']
        
        print(f"\nğŸ“Š {label} (itemid: {itemids})")
        
        # ê° itemidì˜ ë°ì´í„° ì¶”ì¶œ
        itemid_data = {}
        for itemid in itemids:
            # ì‹œê°„ ìœˆë„ìš° ë°ì´í„°
            window_data = labs_long[labs_long['itemid'] == itemid]
            # ì „ì²´ ë°ì´í„°
            all_data = labevents[labevents['itemid'] == itemid]
            
            itemid_data[itemid] = {
                'window_count': len(window_data),
                'total_count': len(all_data),
                'window_values': window_data['valuenum'].dropna() if len(window_data) > 0 else pd.Series(),
                'all_values': all_data['valuenum'].dropna() if len(all_data) > 0 else pd.Series()
            }
        
        # í†µê³„ ë¹„êµ
        print(f"   ë°ì´í„° ìˆ˜:")
        for itemid, data in itemid_data.items():
            print(f"   - {itemid}: ìœˆë„ìš° {data['window_count']}ê±´, ì „ì²´ {data['total_count']}ê±´")
        
        # ê°’ ë²”ìœ„ ë¹„êµ
        print(f"   ê°’ ë²”ìœ„ (ì „ì²´ ë°ì´í„°):")
        for itemid, data in itemid_data.items():
            if len(data['all_values']) > 0:
                mean_val = data['all_values'].mean()
                std_val = data['all_values'].std()
                min_val = data['all_values'].min()
                max_val = data['all_values'].max()
                print(f"   - {itemid}: mean={mean_val:.2f}, std={std_val:.2f}, "
                      f"range=[{min_val:.2f}, {max_val:.2f}]")
        
        # ë™ì¼ í™˜ìì—ì„œ ë‘ itemid ëª¨ë‘ ì¸¡ì •ëœ ê²½ìš° ì°¾ê¸°
        if len(itemids) == 2:
            check_same_patient_measurements(itemids[0], itemids[1], label, labevents)
        
        # ê²°ê³¼ ì €ì¥
        for itemid, data in itemid_data.items():
            if len(data['all_values']) > 0:
                analysis_results.append({
                    'label': label,
                    'itemid': itemid,
                    'count': data['total_count'],
                    'mean': data['all_values'].mean(),
                    'std': data['all_values'].std(),
                    'min': data['all_values'].min(),
                    'max': data['all_values'].max()
                })
    
    return pd.DataFrame(analysis_results)

def check_same_patient_measurements(itemid1, itemid2, label, labevents):
    """ë™ì¼ í™˜ì/ì…ì›ì—ì„œ ë‘ itemidê°€ ëª¨ë‘ ì¸¡ì •ëœ ê²½ìš° í™•ì¸"""
    
    # ê° itemidì˜ í™˜ì/ì…ì› ëª©ë¡
    data1 = labevents[labevents['itemid'] == itemid1]
    data2 = labevents[labevents['itemid'] == itemid2]
    
    if len(data1) > 0 and len(data2) > 0:
        # ê°™ì€ ì…ì›ì—ì„œ ì¸¡ì •ëœ ê²½ìš°
        common_hadm = set(data1['hadm_id'].dropna()) & set(data2['hadm_id'].dropna())
        
        # ê°™ì€ í™˜ìì—ì„œ ì¸¡ì •ëœ ê²½ìš°
        common_subject = set(data1['subject_id']) & set(data2['subject_id'])
        
        print(f"\n   ğŸ” ë™ì‹œ ì¸¡ì • ë¶„ì„:")
        print(f"      - ê°™ì€ ì…ì›ì—ì„œ ë‘˜ ë‹¤ ì¸¡ì •: {len(common_hadm)}ê±´")
        print(f"      - ê°™ì€ í™˜ìì—ì„œ ë‘˜ ë‹¤ ì¸¡ì •: {len(common_subject)}ëª…")
        
        # ë™ì¼ ì…ì›ì—ì„œì˜ ê°’ ë¹„êµ (ìƒ˜í”Œ)
        if len(common_hadm) > 0:
            sample_hadm = list(common_hadm)[:3]  # ìµœëŒ€ 3ê°œ ìƒ˜í”Œ
            print(f"\n   ğŸ“ ë™ì¼ ì…ì› ìƒ˜í”Œ ë¹„êµ:")
            
            for hadm_id in sample_hadm:
                vals1 = data1[data1['hadm_id'] == hadm_id]['valuenum'].dropna()
                vals2 = data2[data2['hadm_id'] == hadm_id]['valuenum'].dropna()
                
                if len(vals1) > 0 and len(vals2) > 0:
                    print(f"      ì…ì› {hadm_id}:")
                    print(f"      - {itemid1}: {vals1.values[0]:.2f}")
                    print(f"      - {itemid2}: {vals2.values[0]:.2f}")
                    if vals1.values[0] != vals2.values[0]:
                        diff_pct = abs(vals1.values[0] - vals2.values[0]) / vals1.values[0] * 100
                        print(f"      - ì°¨ì´: {diff_pct:.1f}%")

def analyze_temporal_patterns(duplicate_active, labevents):
    """ì‹œê°„ì  ì‚¬ìš© íŒ¨í„´ ë¶„ì„"""
    print("\n" + "="*70)
    print("3. ì‹œê°„ì  ì‚¬ìš© íŒ¨í„´")
    print("="*70)
    
    # charttimeì„ datetimeìœ¼ë¡œ ë³€í™˜
    labevents['charttime'] = pd.to_datetime(labevents['charttime'])
    labevents['year'] = labevents['charttime'].dt.year
    
    for label, row in duplicate_active.iterrows():
        itemids = row['itemid']
        
        print(f"\nğŸ“… {label}:")
        
        for itemid in itemids:
            itemid_data = labevents[labevents['itemid'] == itemid]
            if len(itemid_data) > 0:
                year_counts = itemid_data['year'].value_counts().sort_index()
                
                print(f"   itemid {itemid} ì—°ë„ë³„ ì‚¬ìš©:")
                for year, count in year_counts.head().items():
                    print(f"   - {year}: {count}ê±´")

def create_visualizations(analysis_df, duplicate_active):
    """ì‹œê°í™” ìƒì„±"""
    print("\n" + "="*70)
    print("4. ì‹œê°í™” ìƒì„±")
    print("="*70)
    
    if len(duplicate_active) == 0:
        print("ì‹œê°í™”í•  ì¤‘ë³µ í™œì„± ë¼ë²¨ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    
    # 1. ì¤‘ë³µ í™œì„± ë¼ë²¨ë³„ ë°ì´í„° ìˆ˜
    ax1 = axes[0, 0]
    
    # ê° ë¼ë²¨ì˜ ì´ ë°ì´í„° ìˆ˜ ê³„ì‚°
    label_totals = []
    for label, row in duplicate_active.iterrows():
        total = sum(row['data_count'])
        label_totals.append({'label': label[:30], 'total': total})
    
    label_totals_df = pd.DataFrame(label_totals)
    label_totals_df = label_totals_df.sort_values('total', ascending=True)
    
    if len(label_totals_df) > 0:
        ax1.barh(range(len(label_totals_df)), label_totals_df['total'].values)
        ax1.set_yticks(range(len(label_totals_df)))
        ax1.set_yticklabels(label_totals_df['label'].values)
        ax1.set_xlabel('ì´ ë°ì´í„° ìˆ˜')
        ax1.set_title('ì¤‘ë³µ í™œì„± ë¼ë²¨ë³„ ë°ì´í„° ìˆ˜')
    
    # 2. itemidë³„ í‰ê· ê°’ ë¹„êµ (ìƒìœ„ 5ê°œ ë¼ë²¨)
    ax2 = axes[0, 1]
    
    if len(analysis_df) > 0:
        top_labels = analysis_df.groupby('label')['count'].sum().nlargest(5).index
        
        plot_data = []
        for label in top_labels:
            label_data = analysis_df[analysis_df['label'] == label]
            for _, row in label_data.iterrows():
                plot_data.append({
                    'label': label[:15],
                    'itemid': str(row['itemid']),
                    'mean': row['mean']
                })
        
        if plot_data:
            plot_df = pd.DataFrame(plot_data)
            pivot_df = plot_df.pivot(index='label', columns='itemid', values='mean')
            
            pivot_df.plot(kind='bar', ax=ax2)
            ax2.set_xlabel('ê²€ì‚¬ í•­ëª©')
            ax2.set_ylabel('í‰ê· ê°’')
            ax2.set_title('ê°™ì€ ë¼ë²¨ì˜ ë‹¤ë¥¸ itemid í‰ê· ê°’ ë¹„êµ')
            ax2.legend(title='ItemID', bbox_to_anchor=(1.05, 1))
            ax2.tick_params(axis='x', rotation=45)
    
    # 3. ê°’ ë²”ìœ„ ë¹„êµ (ì˜ˆì‹œ)
    ax3 = axes[1, 0]
    
    if len(analysis_df) > 0:
        # ê°€ì¥ ë°ì´í„°ê°€ ë§ì€ ì¤‘ë³µ ë¼ë²¨ ì„ íƒ
        top_label = analysis_df.groupby('label')['count'].sum().idxmax()
        label_data = analysis_df[analysis_df['label'] == top_label]
        
        if len(label_data) > 1:
            itemids = label_data['itemid'].values
            means = label_data['mean'].values
            stds = label_data['std'].values
            
            x_pos = np.arange(len(itemids))
            
            ax3.bar(x_pos, means, yerr=stds, capsize=5, alpha=0.7)
            ax3.set_xticks(x_pos)
            ax3.set_xticklabels([str(i) for i in itemids])
            ax3.set_xlabel('ItemID')
            ax3.set_ylabel('ê°’')
            ax3.set_title(f'{top_label[:40]}\ní‰ê·  Â± í‘œì¤€í¸ì°¨')
    
    # 4. ìš”ì•½ í†µê³„
    ax4 = axes[1, 1]
    ax4.axis('off')
    
    summary_text = f"""
    ì¤‘ë³µ í™œì„± ë¼ë²¨ ë¶„ì„ ìš”ì•½
    
    â€¢ ì´ ì¤‘ë³µ í™œì„± ë¼ë²¨: {len(duplicate_active)}ê°œ
    â€¢ ì˜í–¥ë°›ëŠ” itemid: {sum(len(row['itemid']) for _, row in duplicate_active.iterrows())}ê°œ
    â€¢ ì´ ë°ì´í„°: {sum(sum(row['data_count']) for _, row in duplicate_active.iterrows()):,}ê±´
    
    ì£¼ìš” ë°œê²¬:
    â€¢ ê°™ì€ ê²€ì‚¬ì˜ ë‹¤ë¥¸ ì¸¡ì • ë°©ë²•/ì¥ë¹„
    â€¢ ì‹œê°„ëŒ€ë³„ itemid ì „í™˜
    â€¢ ì¼ë¶€ëŠ” ë™ì¼ í™˜ìì—ì„œ ì¤‘ë³µ ì¸¡ì •
    """
    
    ax4.text(0.1, 0.5, summary_text, fontsize=12, verticalalignment='center')
    
    plt.tight_layout()
    plt.savefig(os.path.join(FIGURE_PATH, 'duplicate_active_analysis.png'), 
                dpi=150, bbox_inches='tight')
    print(f"âœ… ì‹œê°í™” ì €ì¥: duplicate_active_analysis.png")
    
    plt.close()

def save_results(duplicate_active, analysis_df):
    """ê²°ê³¼ ì €ì¥"""
    print("\n" + "="*70)
    print("5. ê²°ê³¼ ì €ì¥")
    print("="*70)
    
    # ì¤‘ë³µ í™œì„± ë¼ë²¨ ì •ë³´ ì €ì¥
    duplicate_summary = []
    for label, row in duplicate_active.iterrows():
        duplicate_summary.append({
            'label': label,
            'itemid_count': len(row['itemid']),
            'itemids': ';'.join(map(str, row['itemid'])),
            'total_data': sum(row['data_count']),
            'data_counts': ';'.join(map(str, row['data_count'])),
            'coverages': ';'.join([f"{c:.1f}%" for c in row['coverage_pct']])
        })
    
    duplicate_summary_df = pd.DataFrame(duplicate_summary)
    duplicate_summary_df.to_csv(os.path.join(DATA_PATH, 'duplicate_active_labels.csv'), index=False)
    
    # ê°’ ë¶„ì„ ê²°ê³¼ ì €ì¥
    if len(analysis_df) > 0:
        analysis_df.to_csv(os.path.join(DATA_PATH, 'duplicate_value_analysis.csv'), index=False)
    
    # JSON ìš”ì•½
    summary = {
        'duplicate_active_labels': len(duplicate_active),
        'total_affected_itemids': sum(len(row['itemid']) for _, row in duplicate_active.iterrows()),
        'total_data_points': int(sum(sum(row['data_count']) for _, row in duplicate_active.iterrows())),
        'labels_with_duplicates': duplicate_active.index.tolist(),
        'findings': [
            "ëŒ€ë¶€ë¶„ ê°™ì€ ê²€ì‚¬ì˜ ë‹¤ë¥¸ ì¸¡ì • ë°©ë²• ë˜ëŠ” ì¥ë¹„",
            "ì¼ë¶€ëŠ” ì‹œê°„ëŒ€ë³„ë¡œ itemid ì „í™˜",
            "ë™ì¼ í™˜ìì—ì„œ ì¤‘ë³µ ì¸¡ì •ë˜ëŠ” ê²½ìš°ë„ ì¡´ì¬",
            "ê°’ ë²”ìœ„ëŠ” ëŒ€ì²´ë¡œ ìœ ì‚¬í•˜ë‚˜ ì¼ë¶€ ì°¨ì´ ì¡´ì¬"
        ]
    }
    
    with open(os.path.join(DATA_PATH, 'duplicate_active_summary.json'), 'w') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… ê²°ê³¼ íŒŒì¼ ì €ì¥ ì™„ë£Œ")
    print(f"   - duplicate_active_labels.csv")
    print(f"   - duplicate_value_analysis.csv")
    print(f"   - duplicate_active_summary.json")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("\n" + "ğŸ”¬ " * 20)
    print(" ì¤‘ë³µ í™œì„± ItemID ë¶„ì„")
    print("ğŸ”¬ " * 20)
    
    # ë°ì´í„° ë¡œë“œ
    items_df, labs_long, labevents = load_data()
    
    # ì¤‘ë³µ í™œì„± ë¼ë²¨ ì°¾ê¸°
    duplicate_active = find_duplicate_active_labels(items_df)
    
    # ê°’ ì°¨ì´ ë¶„ì„
    analysis_df = analyze_value_differences(duplicate_active, labs_long, labevents)
    
    # ì‹œê°„ì  íŒ¨í„´ ë¶„ì„
    analyze_temporal_patterns(duplicate_active, labevents)
    
    # ì‹œê°í™”
    create_visualizations(analysis_df, duplicate_active)
    
    # ê²°ê³¼ ì €ì¥
    save_results(duplicate_active, analysis_df)
    
    print("\n" + "="*70)
    print("âœ… ì¤‘ë³µ í™œì„± ItemID ë¶„ì„ ì™„ë£Œ!")
    print("="*70)
    print(f"\nğŸ“Š í•µì‹¬ ë°œê²¬:")
    print(f"   - ì¤‘ë³µ í™œì„± ë¼ë²¨: {len(duplicate_active)}ê°œ")
    print(f"   - ëŒ€ë¶€ë¶„ ì¸¡ì • ë°©ë²•/ì¥ë¹„ ì°¨ì´ë¡œ ì¸í•œ ì¤‘ë³µ")
    print(f"   - ì¼ë¶€ëŠ” ë™ì¼ í™˜ìì—ì„œ ì¤‘ë³µ ì¸¡ì •")

if __name__ == "__main__":
    main()