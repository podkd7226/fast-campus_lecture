#!/usr/bin/env python3
"""
ì‹œê°„ ìœˆë„ìš° ë¶„ì„ - 1,200ê°œ ì…ì› ê¸°ì¤€ ì ˆëŒ€ê°’ í‰ê°€
ëª¨ë“  ìˆ˜ì¹˜ë¥¼ 1,200ê°œ ì…ì› ê¸°ì¤€ìœ¼ë¡œ ëª…í™•í•˜ê²Œ í‘œí˜„
"""

import pandas as pd
import numpy as np
import os
import json
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime

# ì„¤ì •
BASE_PATH = '/Users/hyungjun/Desktop/fast campus_lecture'
DATA_PATH = os.path.join(BASE_PATH, 'analysis_initial_lab/data')
FIGURE_PATH = os.path.join(BASE_PATH, 'analysis_initial_lab/figures')

# í´ë” ìƒì„±
os.makedirs(FIGURE_PATH, exist_ok=True)

def load_data():
    """ë°ì´í„° ë¡œë“œ"""
    print("ë°ì´í„° ë¡œë”© ì¤‘...")
    
    # 1. ì…ì› ë‹¹ì¼ë§Œ ë°ì´í„°
    day0_wide = pd.read_csv(os.path.join(DATA_PATH, 'initial_labs_wide.csv'))
    
    # 2. ì‹œê°„ ìœˆë„ìš° ë°ì´í„°
    window_wide = pd.read_csv(os.path.join(DATA_PATH, 'labs_time_window_wide.csv'))
    window_long = pd.read_csv(os.path.join(DATA_PATH, 'labs_time_window_long.csv'))
    
    # 3. í†µê³„ ë°ì´í„°
    with open(os.path.join(DATA_PATH, 'lab_statistics.json'), 'r') as f:
        stats_day0 = json.load(f)
    
    with open(os.path.join(DATA_PATH, 'lab_statistics_time_window.json'), 'r') as f:
        stats_window = json.load(f)
    
    print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
    
    return day0_wide, window_wide, window_long, stats_day0, stats_window

def analyze_absolute_values(day0_wide, window_wide, window_long):
    """1,200ê°œ ì…ì› ê¸°ì¤€ ì ˆëŒ€ê°’ ë¶„ì„"""
    print("\n" + "="*80)
    print("ğŸ“Š 1,200ê°œ ì…ì› ê¸°ì¤€ ì ˆëŒ€ê°’ ë¶„ì„")
    print("="*80)
    
    # ê¸°ë³¸ ê²€ì‚¬ ì»¬ëŸ¼ (day_offset ì œì™¸)
    lab_columns = [col for col in window_wide.columns 
                   if col not in ['hadm_id', 'subject_id', 'admittime', 'hospital_expire_flag', 'admit_date'] 
                   and '_day_offset' not in col]
    
    results = {}
    
    print("\n### ì „ì²´ ìš”ì•½ (1,200ê°œ ì…ì› ê¸°ì¤€)")
    print("-" * 60)
    
    # 1. ì „ì²´ ê°€ìš©ì„±
    has_lab_day0 = ~day0_wide[lab_columns].isna().all(axis=1)
    has_lab_window = ~window_wide[lab_columns].isna().all(axis=1)
    
    n_day0 = has_lab_day0.sum()
    n_window = has_lab_window.sum()
    n_improved = n_window - n_day0
    
    print(f"ì…ì› ë‹¹ì¼ë§Œ:")
    print(f"  - ê²€ì‚¬ ìˆìŒ: {n_day0}ê±´ ({n_day0/1200*100:.1f}%)")
    print(f"  - ê²€ì‚¬ ì—†ìŒ: {1200-n_day0}ê±´ ({(1200-n_day0)/1200*100:.1f}%)")
    
    print(f"\nì‹œê°„ ìœˆë„ìš° ì ìš©:")
    print(f"  - ê²€ì‚¬ ìˆìŒ: {n_window}ê±´ ({n_window/1200*100:.1f}%)")
    print(f"  - ê²€ì‚¬ ì—†ìŒ: {1200-n_window}ê±´ ({(1200-n_window)/1200*100:.1f}%)")
    
    print(f"\nê°œì„  íš¨ê³¼:")
    print(f"  - ì¶”ê°€ëœ ì…ì›: {n_improved}ê±´ ({n_improved/1200*100:.1f}%p ì¦ê°€)")
    
    # 2. ê²€ì‚¬ë³„ ìƒì„¸ ë¶„ì„
    print("\n### ê²€ì‚¬ë³„ ê°€ìš©ì„± (1,200ê°œ ì…ì› ê¸°ì¤€)")
    print("-" * 60)
    
    lab_analysis = []
    
    for lab in lab_columns:
        # Day 0ë§Œ
        n_day0_lab = day0_wide[lab].notna().sum()
        pct_day0_lab = n_day0_lab / 1200 * 100
        
        # ì‹œê°„ ìœˆë„ìš°
        n_window_lab = window_wide[lab].notna().sum()
        pct_window_lab = n_window_lab / 1200 * 100
        
        # ê°œì„ 
        n_improved_lab = n_window_lab - n_day0_lab
        pct_improved_lab = pct_window_lab - pct_day0_lab
        
        # Day offset ë¶„ì„ (ì–´ë””ì„œ ë°ì´í„°ê°€ ì™”ëŠ”ì§€)
        offset_col = f"{lab}_day_offset"
        if offset_col in window_wide.columns:
            day_sources = window_wide[window_wide[lab].notna()][offset_col].value_counts().to_dict()
            n_from_day0 = day_sources.get(0.0, 0)
            n_from_minus1 = day_sources.get(-1.0, 0)
            n_from_plus1 = day_sources.get(1.0, 0)
        else:
            n_from_day0 = n_from_minus1 = n_from_plus1 = 0
        
        lab_analysis.append({
            'lab_name': lab,
            'day0_count': n_day0_lab,
            'day0_pct': pct_day0_lab,
            'window_count': n_window_lab,
            'window_pct': pct_window_lab,
            'improved_count': n_improved_lab,
            'improved_pct': pct_improved_lab,
            'from_day0': n_from_day0,
            'from_minus1': n_from_minus1,
            'from_plus1': n_from_plus1
        })
    
    # DataFrameìœ¼ë¡œ ë³€í™˜ ë° ì •ë ¬
    lab_df = pd.DataFrame(lab_analysis)
    lab_df = lab_df.sort_values('improved_count', ascending=False)
    
    # ìƒìœ„ 10ê°œ ì¶œë ¥
    print("\nğŸ“ˆ ê°€ìš©ì„± ê°œì„  ìƒìœ„ 10ê°œ ê²€ì‚¬")
    print("-" * 100)
    print(f"{'ê²€ì‚¬ëª…':<30} | {'ë‹¹ì¼ë§Œ':<20} | {'ì‹œê°„ìœˆë„ìš°':<20} | {'ê°œì„ ':<15} | {'ë°ì´í„° ì¶œì²˜'}")
    print("-" * 100)
    
    for _, row in lab_df.head(10).iterrows():
        print(f"{row['lab_name']:<30} | "
              f"{row['day0_count']:>4}ê±´ ({row['day0_pct']:>5.1f}%) | "
              f"{row['window_count']:>4}ê±´ ({row['window_pct']:>5.1f}%) | "
              f"+{row['improved_count']:>3}ê±´ (+{row['improved_pct']:>4.1f}%p) | "
              f"D0:{row['from_day0']:>4}, D-1:{row['from_minus1']:>3}, D+1:{row['from_plus1']:>3}")
    
    # 3. ë°ì´í„° ì¶œì²˜ ë¶„ì„ (ì „ì²´)
    print("\n### ì „ì²´ ë°ì´í„° ì¶œì²˜ ë¶„ì„ (20,118ê°œ ê²€ì‚¬ ë ˆì½”ë“œ)")
    print("-" * 60)
    
    if 'day_offset' in window_long.columns:
        source_counts = window_long['day_offset'].value_counts().sort_index()
        
        print(f"Day-1 (ì…ì› ì „ì¼): {source_counts.get(-1, 0):>5}ê±´ ({source_counts.get(-1, 0)/len(window_long)*100:>5.1f}%)")
        print(f"Day 0 (ì…ì› ë‹¹ì¼): {source_counts.get(0, 0):>5}ê±´ ({source_counts.get(0, 0)/len(window_long)*100:>5.1f}%)")
        print(f"Day+1 (ì…ì› ìµì¼): {source_counts.get(1, 0):>5}ê±´ ({source_counts.get(1, 0)/len(window_long)*100:>5.1f}%)")
    
    # 4. ì™„ì „ ê²°ì¸¡ ì…ì› ë¶„ì„
    print("\n### ì™„ì „ ê²°ì¸¡ ì…ì› ë¶„ì„")
    print("-" * 60)
    
    # ë‹¹ì¼ë§Œì—ì„œ ê²°ì¸¡ì¸ ì…ì›
    no_lab_day0 = day0_wide[~has_lab_day0]['hadm_id'].tolist()
    # ì‹œê°„ ìœˆë„ìš°ì—ì„œë„ ì—¬ì „íˆ ê²°ì¸¡ì¸ ì…ì›
    no_lab_window = window_wide[~has_lab_window]['hadm_id'].tolist()
    # ì‹œê°„ ìœˆë„ìš°ë¡œ í•´ê²°ëœ ì…ì›
    resolved = set(no_lab_day0) - set(no_lab_window)
    
    print(f"ë‹¹ì¼ ê²€ì‚¬ ì—†ìŒ: {len(no_lab_day0)}ê±´")
    print(f"ì‹œê°„ ìœˆë„ìš°ë¡œ í•´ê²°: {len(resolved)}ê±´")
    print(f"ì—¬ì „íˆ ê²€ì‚¬ ì—†ìŒ: {len(no_lab_window)}ê±´")
    
    return lab_df

def create_absolute_visualization(lab_df):
    """ì ˆëŒ€ê°’ ê¸°ì¤€ ì‹œê°í™”"""
    print("\nì‹œê°í™” ìƒì„± ì¤‘...")
    
    # ì„¤ì •
    plt.rcParams['font.family'] = 'DejaVu Sans'
    plt.rcParams['font.size'] = 10
    
    # Figure ìƒì„±
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    
    # 1. ì „ì²´ ê°€ìš©ì„± ë¹„êµ (ë§‰ëŒ€ê·¸ë˜í”„)
    ax1 = axes[0, 0]
    categories = ['ì…ì› ë‹¹ì¼ë§Œ', 'ì‹œê°„ ìœˆë„ìš°']
    has_lab = [1053, 1155]  # ì‹¤ì œ ë°ì´í„°
    no_lab = [147, 45]
    
    x = np.arange(len(categories))
    width = 0.35
    
    bars1 = ax1.bar(x - width/2, has_lab, width, label='ê²€ì‚¬ ìˆìŒ', color='#2E86AB')
    bars2 = ax1.bar(x + width/2, no_lab, width, label='ê²€ì‚¬ ì—†ìŒ', color='#A23B72')
    
    # ë§‰ëŒ€ ìœ„ì— ìˆ˜ì¹˜ í‘œì‹œ
    for bar in bars1:
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height,
                f'{int(height)}ê±´\n({height/12:.1f}%)',
                ha='center', va='bottom')
    
    for bar in bars2:
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height,
                f'{int(height)}ê±´\n({height/12:.1f}%)',
                ha='center', va='bottom')
    
    ax1.set_ylabel('ì…ì› ìˆ˜')
    ax1.set_title('ì „ì²´ ê°€ìš©ì„± ë¹„êµ (1,200ê°œ ì…ì› ê¸°ì¤€)')
    ax1.set_xticks(x)
    ax1.set_xticklabels(categories)
    ax1.legend()
    ax1.set_ylim(0, 1300)
    ax1.grid(axis='y', alpha=0.3)
    
    # 2. ê²€ì‚¬ë³„ ê°œì„  íš¨ê³¼ (ìƒìœ„ 15ê°œ)
    ax2 = axes[0, 1]
    top15 = lab_df.head(15)
    
    y_pos = np.arange(len(top15))
    ax2.barh(y_pos, top15['day0_count'], 0.4, 
             label='ë‹¹ì¼ë§Œ', color='#5C946E', alpha=0.7)
    ax2.barh(y_pos + 0.4, top15['window_count'], 0.4,
             label='ì‹œê°„ ìœˆë„ìš°', color='#2E86AB', alpha=0.7)
    
    ax2.set_yticks(y_pos + 0.2)
    ax2.set_yticklabels(top15['lab_name'], fontsize=8)
    ax2.set_xlabel('ê²€ì‚¬ ê°€ëŠ¥í•œ ì…ì› ìˆ˜')
    ax2.set_title('ê²€ì‚¬ë³„ ê°€ìš©ì„± ê°œì„  (ìƒìœ„ 15ê°œ)')
    ax2.legend()
    ax2.grid(axis='x', alpha=0.3)
    
    # 3. ë°ì´í„° ì¶œì²˜ ë¶„í¬ (íŒŒì´ ì°¨íŠ¸)
    ax3 = axes[1, 0]
    sizes = [1065, 16593, 2460]  # Day-1, Day0, Day+1
    labels = ['Day-1\n(ì…ì› ì „ì¼)\n1,065ê±´\n5.3%', 
              'Day 0\n(ì…ì› ë‹¹ì¼)\n16,593ê±´\n82.5%', 
              'Day+1\n(ì…ì› ìµì¼)\n2,460ê±´\n12.2%']
    colors = ['#F18F01', '#2E86AB', '#A23B72']
    explode = (0.1, 0, 0.1)
    
    ax3.pie(sizes, explode=explode, labels=labels, colors=colors,
            autopct='', shadow=True, startangle=90)
    ax3.set_title('ì „ì²´ ê²€ì‚¬ ë ˆì½”ë“œ ì¶œì²˜ ë¶„í¬ (20,118ê±´)')
    
    # 4. ê°œì„ ìœ¨ ë¶„í¬ (íˆìŠ¤í† ê·¸ë¨)
    ax4 = axes[1, 1]
    improvements = lab_df['improved_pct'].values
    
    ax4.hist(improvements, bins=20, color='#2E86AB', alpha=0.7, edgecolor='black')
    ax4.axvline(x=improvements.mean(), color='red', linestyle='--', 
                label=f'í‰ê· : {improvements.mean():.1f}%p')
    ax4.set_xlabel('ê°€ìš©ì„± ê°œì„  (%p)')
    ax4.set_ylabel('ê²€ì‚¬ í•­ëª© ìˆ˜')
    ax4.set_title('ê²€ì‚¬ë³„ ê°€ìš©ì„± ê°œì„ ìœ¨ ë¶„í¬')
    ax4.legend()
    ax4.grid(axis='y', alpha=0.3)
    
    plt.suptitle('ì‹œê°„ ìœˆë„ìš° íš¨ê³¼ ë¶„ì„ - 1,200ê°œ ì…ì› ê¸°ì¤€ ì ˆëŒ€ê°’', 
                 fontsize=14, fontweight='bold', y=1.02)
    plt.tight_layout()
    
    # ì €ì¥
    output_path = os.path.join(FIGURE_PATH, 'time_window_absolute_analysis.png')
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"âœ… ì‹œê°í™” ì €ì¥: {output_path}")
    plt.show()

def save_results(lab_df):
    """ê²°ê³¼ ì €ì¥"""
    print("\nê²°ê³¼ ì €ì¥ ì¤‘...")
    
    # CSV ì €ì¥
    output_path = os.path.join(DATA_PATH, 'time_window_absolute_analysis.csv')
    lab_df.to_csv(output_path, index=False)
    print(f"âœ… ë¶„ì„ ê²°ê³¼ ì €ì¥: {output_path}")
    
    # ìš”ì•½ í†µê³„ JSON
    summary = {
        "analysis_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "total_admissions": 1200,
        "admission_day_only": {
            "with_labs": 1053,
            "without_labs": 147,
            "coverage_pct": 87.75
        },
        "time_window": {
            "with_labs": 1155,
            "without_labs": 45,
            "coverage_pct": 96.25
        },
        "improvement": {
            "additional_admissions": 102,
            "improvement_pct": 8.5
        },
        "data_sources": {
            "total_records": 20118,
            "day_minus1": 1065,
            "day0": 16593,
            "day_plus1": 2460,
            "day_minus1_pct": 5.29,
            "day0_pct": 82.48,
            "day_plus1_pct": 12.23
        },
        "top_improvements": lab_df.head(10).to_dict('records')
    }
    
    json_path = os.path.join(DATA_PATH, 'time_window_absolute_summary.json')
    with open(json_path, 'w') as f:
        json.dump(summary, f, indent=2)
    print(f"âœ… ìš”ì•½ í†µê³„ ì €ì¥: {json_path}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("\n" + "="*80)
    print("ğŸ” ì‹œê°„ ìœˆë„ìš° ë¶„ì„ - 1,200ê°œ ì…ì› ê¸°ì¤€ ì ˆëŒ€ê°’ í‰ê°€")
    print("="*80)
    
    # 1. ë°ì´í„° ë¡œë“œ
    day0_wide, window_wide, window_long, stats_day0, stats_window = load_data()
    
    # 2. ì ˆëŒ€ê°’ ë¶„ì„
    lab_df = analyze_absolute_values(day0_wide, window_wide, window_long)
    
    # 3. ì‹œê°í™”
    create_absolute_visualization(lab_df)
    
    # 4. ê²°ê³¼ ì €ì¥
    save_results(lab_df)
    
    print("\n" + "="*80)
    print("âœ… ë¶„ì„ ì™„ë£Œ!")
    print("="*80)

if __name__ == "__main__":
    main()